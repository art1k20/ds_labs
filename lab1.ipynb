{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "NOAAIndex = {\n",
    "        1:24,\n",
    "        2:25,\n",
    "        3:5,\n",
    "        4:6,\n",
    "        5:27,\n",
    "        6:23,\n",
    "        7:26,\n",
    "        8:7,\n",
    "        9:11,\n",
    "        10:13,\n",
    "        11:14,\n",
    "        12:15,\n",
    "        13:16,\n",
    "        14:17,\n",
    "        15:18,\n",
    "        16:19,\n",
    "        17:21,\n",
    "        18:22,\n",
    "        19:8,\n",
    "        20:9,\n",
    "        21:10,\n",
    "        22:1,\n",
    "        23:3,\n",
    "        24:2,\n",
    "        25:4, \n",
    "        26:12, #Kiev\n",
    "        27:20 #Sevastopol\n",
    "}\n",
    "\n",
    "def download_data( index, minYear=1991, maxYear=2022): \n",
    "    now = datetime.now()\n",
    "    now = \"{}.{}.{}_{}-{}\".format(now.day, now.month, now.year, now.hour, now.minute)\n",
    "    url = \"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={}&year1={}&year2={}&type=Mean\".format(NOAAIndex[index], minYear, maxYear)\n",
    "    destination = f'{index}_{now}.csv'\n",
    "    urllib.request.urlretrieve(url, destination)\n",
    "for i in range(1,28):\n",
    "    download_data(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'empty']\n",
    "df = pd.read_csv(r\"C:\\Users\\valer\\Desktop\\DS lab 1\\1_3.10.2022_20-41.csv\", header = 1, names = headers)\n",
    "df = df.drop(df.loc[df['VHI'] == -1].index)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.84\n"
     ]
    }
   ],
   "source": [
    "def max_v(year):\n",
    "    return df[(df.Year.astype(str)==str(year)) & (df.VHI != -1)]['VHI'].max()\n",
    "print(max_v(1995))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.85\n"
     ]
    }
   ],
   "source": [
    "def min_v(year):\n",
    "    return df[(df.Year.astype(str)==str(year)) & (df.VHI != -1)]['VHI'].min()\n",
    "\n",
    "print(min_v(1995))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Week    SMN     SMT    VCI    TCI    VHI  empty\n",
      "512  2000    45  0.070  278.30   6.71  17.80  12.26    NaN\n",
      "513  2000    46  0.055  276.68   7.14  15.43  11.28    NaN\n",
      "514  2000    47  0.041  274.89   7.55  14.94  11.25    NaN\n",
      "515  2000    48  0.032  273.63   9.03  13.73  11.38    NaN\n",
      "516  2000    49  0.031  272.13  11.81  14.01  12.91    NaN\n",
      "517  2000    50  0.030  270.44  14.30  14.10  14.20    NaN\n"
     ]
    }
   ],
   "source": [
    "def drought():\n",
    "  return  df[(df.VHI <= 15) & (df.VHI != -1)]\n",
    "\n",
    "print(drought())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
